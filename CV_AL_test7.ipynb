{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DOI03/DOI03/blob/main/CV_AL_test7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   optimizer로 AdamP 사용\n",
        "2.   lr 0.0001\n",
        "3.   epoch 25\n",
        "4.   get_cosine_schedule 스케줄러 사용\n",
        "\n"
      ],
      "metadata": {
        "id": "JBBnibyCbQ_A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xr4ox9es1m_Z",
        "outputId": "a5f75e3e-8a49-48ba-fb14-3718f31d6337"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb\n",
        "!pip install adamp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7a36Uzf7yL9l",
        "outputId": "5d75a2f7-c36d-4ece-bf92-3714469c1d33"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.18.5)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.43)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.17.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (75.1.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.10/dist-packages (from wandb) (4.12.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.8.30)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n",
            "Requirement already satisfied: adamp in /usr/local/lib/python3.10/dist-packages (0.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "qOc0tT3-nv73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "cf42a6cb-b4dd-45e8-a7b3-768377feac15"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing last run (ID:l8m3m3mp) before initializing another..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">AdamP_with_get_cosine_schedule</strong> at: <a href='https://wandb.ai/parkdoi-gachon-university/CUB_Transfer_Learning/runs/l8m3m3mp' target=\"_blank\">https://wandb.ai/parkdoi-gachon-university/CUB_Transfer_Learning/runs/l8m3m3mp</a><br/> View project at: <a href='https://wandb.ai/parkdoi-gachon-university/CUB_Transfer_Learning' target=\"_blank\">https://wandb.ai/parkdoi-gachon-university/CUB_Transfer_Learning</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20241025_135349-l8m3m3mp/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Successfully finished last run (ID:l8m3m3mp). Initializing new run:<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.18.5"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241025_135702-1rnukd12</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/parkdoi-gachon-university/CUB_Transfer_Learning/runs/1rnukd12' target=\"_blank\">AdamP_with_get_cosine_schedule</a></strong> to <a href='https://wandb.ai/parkdoi-gachon-university/CUB_Transfer_Learning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/parkdoi-gachon-university/CUB_Transfer_Learning' target=\"_blank\">https://wandb.ai/parkdoi-gachon-university/CUB_Transfer_Learning</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/parkdoi-gachon-university/CUB_Transfer_Learning/runs/1rnukd12' target=\"_blank\">https://wandb.ai/parkdoi-gachon-university/CUB_Transfer_Learning/runs/1rnukd12</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import time\n",
        "\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import wandb\n",
        "\n",
        "# AdamP 사용\n",
        "from adamp import AdamP\n",
        "\n",
        "from PIL import Image\n",
        "#내가 추가\n",
        "import re\n",
        "\n",
        "from transformers import get_cosine_schedule_with_warmup\n",
        "\n",
        "### wandb 설정 ###\n",
        "wandb.init(project=\"CUB_Transfer_Learning\", name=\"AdamP_with_get_cosine_schedule\")\n",
        "\n",
        "### GPU Setting ###\n",
        "USE_CUDA = torch.cuda.is_available()\n",
        "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
        "print(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Custom Dataset ###\n",
        "class CUB2011(Dataset):\n",
        "  def __init__(self, transform, mode='train'):\n",
        "    self.transform = transform\n",
        "    self.mode = mode\n",
        "\n",
        "    if self.mode == 'train':\n",
        "      self.image_folder = os.listdir('/content/gdrive/MyDrive/CUB_200_2011_repackage_class50/datasets/train')\n",
        "    elif self.mode == 'valid':\n",
        "      self.image_folder = os.listdir('/content/gdrive/MyDrive/CUB_200_2011_repackage_class50/datasets/valid')\n",
        "    elif self.mode == 'test':\n",
        "      self.image_folder = os.listdir('/content/gdrive/MyDrive/CUB_200_2011_repackage_class50/datasets/test')\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.image_folder)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    img_path = self.image_folder[idx]\n",
        "    img = Image.open(os.path.join('/content/gdrive/MyDrive/CUB_200_2011_repackage_class50/datasets', self.mode, img_path)).convert('RGB')\n",
        "    img = self.transform(img)\n",
        "    label = img_path.split('_')[-1].split('.')[0]\n",
        "    label = re.sub(r'\\([^)]*\\)', '', label)\n",
        "    label = int(label)\n",
        "    return (img, label)"
      ],
      "metadata": {
        "id": "KaFgjkFp8tzI"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Data Preprocessing ###\n",
        "\n",
        "'''\n",
        "# 데이터 정규화 추가\n",
        "# 정규화 변환 정의\n",
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "'''\n",
        "transforms_train = transforms.Compose([transforms.Resize((448,448)),\n",
        "                                       transforms.ToTensor()])\n",
        "transforms_valtest = transforms.Compose([transforms.Resize((448,448)),\n",
        "                                         transforms.ToTensor()])\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "train_set = CUB2011(mode='train',\n",
        "                    transform=transforms_train)\n",
        "# transforms_train을 transforms_valtest로 변경\n",
        "val_set = CUB2011(mode='valid',\n",
        "                  transform=transforms_valtest)\n",
        "test_set = CUB2011(mode='test',\n",
        "                  transform=transforms_valtest)\n",
        "\n",
        "print('Num of each dataset: ',len(train_set),len(val_set),len(test_set))\n",
        "\n",
        "train_loader = DataLoader(train_set,batch_size=BATCH_SIZE,shuffle=True)\n",
        "val_loader = DataLoader(val_set,batch_size=BATCH_SIZE,shuffle=False)\n",
        "test_loader = DataLoader(test_set,batch_size=BATCH_SIZE,shuffle=False)\n",
        "\n",
        "print(\"Loaded dataloader\")\n",
        "\n",
        "### Model / Optimizer ###\n",
        "EPOCH = 25\n",
        "lr = 0.0001\n",
        "\n",
        "model = models.resnet18(pretrained=True)\n",
        "\n",
        "### Tranfer Learning ###\n",
        "num_features = model.fc.in_features\n",
        "model.fc = nn.Linear(num_features,50)\n",
        "model.to(DEVICE)\n",
        "\n",
        "optimizer = AdamP(model.parameters(), lr=lr)\n",
        "\n",
        "# 스케줄러 초기화 (get_cosine_schedule_with_warmup 사용)\n",
        "total_steps = len(train_loader) * EPOCH\n",
        "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=total_steps // 10, num_training_steps=total_steps)\n",
        "\n",
        "print(\"Created a learning model and optimizer\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38vx5jj22neg",
        "outputId": "d7c4648c-bd04-4c21-cbeb-6fb6afe580a6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num of each dataset:  2360 296 298\n",
            "Loaded dataloader\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 68.6MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created a learning model and optimizer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Train/Evaluation ###\n",
        "def train(model, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    train_loss_total = 0\n",
        "    for i, (image, target) in enumerate(train_loader):\n",
        "        image, target = image.to(DEVICE), target.to(DEVICE)\n",
        "        output = model(image)\n",
        "        optimizer.zero_grad()\n",
        "        train_loss = F.cross_entropy(output, target).to(DEVICE)\n",
        "\n",
        "        train_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss_total += train_loss.item()\n",
        "\n",
        "        if i % 10 == 0:\n",
        "            print(f'Train Epoch: {epoch} [{i}/{len(train_loader)}]\\tloss: {train_loss.item():.6f}')\n",
        "\n",
        "    avg_train_loss = train_loss_total / len(train_loader)\n",
        "    return avg_train_loss\n",
        "\n",
        "def evaluate(model, val_loader):\n",
        "    model.eval()\n",
        "    eval_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for i, (image, target) in enumerate(val_loader):\n",
        "            image, target = image.to(DEVICE), target.to(DEVICE)\n",
        "            output = model(image)\n",
        "\n",
        "            eval_loss += F.cross_entropy(output, target, reduction='sum').item()\n",
        "            pred = output.max(1, keepdim=True)[1]\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    eval_loss /= len(val_loader.dataset)\n",
        "    eval_accuracy = 100 * correct / len(val_loader.dataset)\n",
        "    return eval_loss, eval_accuracy"
      ],
      "metadata": {
        "id": "apDhVk6C2r7R"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Main ###\n",
        "start = time.time()\n",
        "best = 0\n",
        "for epoch in range(EPOCH):\n",
        "    train_loss = train(model, train_loader, optimizer, epoch)\n",
        "    val_loss, val_accuracy = evaluate(model, val_loader)\n",
        "\n",
        "    # 스케줄러 업데이트 (에포크가 끝난 후)\n",
        "    scheduler.step()\n",
        "\n",
        "    # wandb 로그 기록\n",
        "    wandb.log({\n",
        "        'Epoch': epoch,\n",
        "        'Train Loss': train_loss,\n",
        "        'Validation Loss': val_loss,\n",
        "        'Validation Accuracy': val_accuracy\n",
        "    })\n",
        "\n",
        "    # Save best model\n",
        "    if val_accuracy > best:\n",
        "        best = val_accuracy\n",
        "        torch.save(model.state_dict(), \"./best_model.pth\")\n",
        "\n",
        "    print(f\"[{epoch}] Validation Loss: {val_loss:.4f}, Accuracy: {val_accuracy:.4f}%\")\n",
        "\n",
        "# Test result\n",
        "test_loss, test_accuracy = evaluate(model, test_loader)\n",
        "print(f'[FINAL] Test Loss: {test_loss:.4f}, Accuracy: {test_accuracy:.4f}%')\n",
        "\n",
        "# wandb 테스트 결과 로그 기록\n",
        "wandb.log({\n",
        "    'Test Loss': test_loss,\n",
        "    'Test Accuracy': test_accuracy\n",
        "})\n",
        "\n",
        "end = time.time()\n",
        "elapsed_time = end - start\n",
        "\n",
        "print(\"Best Accuracy: \", best)\n",
        "print(f\"Elapsed Time: {int(elapsed_time / 3600)}h, {int(elapsed_time / 60)}m, {int(elapsed_time % 60)}s\")\n",
        "\n",
        "wandb.finish()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VNhSTX452wyd",
        "outputId": "707bb9e9-d59d-406f-918d-b4524057b22b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 0 [0/74]\tloss: 3.995575\n",
            "Train Epoch: 0 [10/74]\tloss: 4.097239\n",
            "Train Epoch: 0 [20/74]\tloss: 4.014915\n",
            "Train Epoch: 0 [30/74]\tloss: 4.084760\n",
            "Train Epoch: 0 [40/74]\tloss: 3.996701\n",
            "Train Epoch: 0 [50/74]\tloss: 4.192347\n",
            "Train Epoch: 0 [60/74]\tloss: 4.165475\n",
            "Train Epoch: 0 [70/74]\tloss: 4.137008\n",
            "[0] Validation Loss: 4.0482, Accuracy: 2.3649%\n",
            "Train Epoch: 1 [0/74]\tloss: 4.157443\n",
            "Train Epoch: 1 [10/74]\tloss: 4.093915\n",
            "Train Epoch: 1 [20/74]\tloss: 4.002744\n",
            "Train Epoch: 1 [30/74]\tloss: 4.083667\n",
            "Train Epoch: 1 [40/74]\tloss: 4.067531\n",
            "Train Epoch: 1 [50/74]\tloss: 4.148960\n",
            "Train Epoch: 1 [60/74]\tloss: 4.003203\n",
            "Train Epoch: 1 [70/74]\tloss: 4.105718\n",
            "[1] Validation Loss: 4.0333, Accuracy: 2.3649%\n",
            "Train Epoch: 2 [0/74]\tloss: 3.918234\n",
            "Train Epoch: 2 [10/74]\tloss: 3.966890\n",
            "Train Epoch: 2 [20/74]\tloss: 4.042470\n",
            "Train Epoch: 2 [30/74]\tloss: 4.037005\n",
            "Train Epoch: 2 [40/74]\tloss: 4.053275\n",
            "Train Epoch: 2 [50/74]\tloss: 4.055900\n",
            "Train Epoch: 2 [60/74]\tloss: 4.014310\n",
            "Train Epoch: 2 [70/74]\tloss: 4.098948\n",
            "[2] Validation Loss: 3.9991, Accuracy: 2.7027%\n",
            "Train Epoch: 3 [0/74]\tloss: 4.081212\n",
            "Train Epoch: 3 [10/74]\tloss: 4.069227\n",
            "Train Epoch: 3 [20/74]\tloss: 4.049528\n",
            "Train Epoch: 3 [30/74]\tloss: 3.929080\n",
            "Train Epoch: 3 [40/74]\tloss: 4.114552\n",
            "Train Epoch: 3 [50/74]\tloss: 4.137081\n",
            "Train Epoch: 3 [60/74]\tloss: 4.057420\n",
            "Train Epoch: 3 [70/74]\tloss: 3.850555\n",
            "[3] Validation Loss: 3.9510, Accuracy: 4.7297%\n",
            "Train Epoch: 4 [0/74]\tloss: 4.019548\n",
            "Train Epoch: 4 [10/74]\tloss: 3.912153\n",
            "Train Epoch: 4 [20/74]\tloss: 3.893449\n",
            "Train Epoch: 4 [30/74]\tloss: 4.035259\n",
            "Train Epoch: 4 [40/74]\tloss: 3.978958\n",
            "Train Epoch: 4 [50/74]\tloss: 4.124840\n",
            "Train Epoch: 4 [60/74]\tloss: 3.936879\n",
            "Train Epoch: 4 [70/74]\tloss: 3.973478\n",
            "[4] Validation Loss: 3.8897, Accuracy: 5.4054%\n",
            "Train Epoch: 5 [0/74]\tloss: 4.036490\n",
            "Train Epoch: 5 [10/74]\tloss: 3.851341\n",
            "Train Epoch: 5 [20/74]\tloss: 3.841348\n",
            "Train Epoch: 5 [30/74]\tloss: 3.803981\n",
            "Train Epoch: 5 [40/74]\tloss: 3.941457\n",
            "Train Epoch: 5 [50/74]\tloss: 3.749615\n",
            "Train Epoch: 5 [60/74]\tloss: 3.875100\n",
            "Train Epoch: 5 [70/74]\tloss: 3.683985\n",
            "[5] Validation Loss: 3.8170, Accuracy: 6.0811%\n",
            "Train Epoch: 6 [0/74]\tloss: 3.725152\n",
            "Train Epoch: 6 [10/74]\tloss: 3.844089\n",
            "Train Epoch: 6 [20/74]\tloss: 3.949471\n",
            "Train Epoch: 6 [30/74]\tloss: 3.627048\n",
            "Train Epoch: 6 [40/74]\tloss: 3.758061\n",
            "Train Epoch: 6 [50/74]\tloss: 3.864299\n",
            "Train Epoch: 6 [60/74]\tloss: 3.643063\n",
            "Train Epoch: 6 [70/74]\tloss: 3.784365\n",
            "[6] Validation Loss: 3.7316, Accuracy: 7.7703%\n",
            "Train Epoch: 7 [0/74]\tloss: 3.695383\n",
            "Train Epoch: 7 [10/74]\tloss: 3.630161\n",
            "Train Epoch: 7 [20/74]\tloss: 3.580017\n",
            "Train Epoch: 7 [30/74]\tloss: 3.632046\n",
            "Train Epoch: 7 [40/74]\tloss: 3.541755\n",
            "Train Epoch: 7 [50/74]\tloss: 3.532167\n",
            "Train Epoch: 7 [60/74]\tloss: 3.660115\n",
            "Train Epoch: 7 [70/74]\tloss: 3.717263\n",
            "[7] Validation Loss: 3.6350, Accuracy: 8.7838%\n",
            "Train Epoch: 8 [0/74]\tloss: 3.601762\n",
            "Train Epoch: 8 [10/74]\tloss: 3.560789\n",
            "Train Epoch: 8 [20/74]\tloss: 3.545704\n",
            "Train Epoch: 8 [30/74]\tloss: 3.413428\n",
            "Train Epoch: 8 [40/74]\tloss: 3.614122\n",
            "Train Epoch: 8 [50/74]\tloss: 3.546208\n",
            "Train Epoch: 8 [60/74]\tloss: 3.528135\n",
            "Train Epoch: 8 [70/74]\tloss: 3.446685\n",
            "[8] Validation Loss: 3.5261, Accuracy: 12.5000%\n",
            "Train Epoch: 9 [0/74]\tloss: 3.535064\n",
            "Train Epoch: 9 [10/74]\tloss: 3.301718\n",
            "Train Epoch: 9 [20/74]\tloss: 3.139925\n",
            "Train Epoch: 9 [30/74]\tloss: 3.294670\n",
            "Train Epoch: 9 [40/74]\tloss: 3.312699\n",
            "Train Epoch: 9 [50/74]\tloss: 3.400719\n",
            "Train Epoch: 9 [60/74]\tloss: 3.435292\n",
            "Train Epoch: 9 [70/74]\tloss: 3.221334\n",
            "[9] Validation Loss: 3.4061, Accuracy: 17.5676%\n",
            "Train Epoch: 10 [0/74]\tloss: 3.255749\n",
            "Train Epoch: 10 [10/74]\tloss: 3.227741\n",
            "Train Epoch: 10 [20/74]\tloss: 3.209822\n",
            "Train Epoch: 10 [30/74]\tloss: 3.021945\n",
            "Train Epoch: 10 [40/74]\tloss: 3.365567\n",
            "Train Epoch: 10 [50/74]\tloss: 3.198142\n",
            "Train Epoch: 10 [60/74]\tloss: 3.180188\n",
            "Train Epoch: 10 [70/74]\tloss: 2.979897\n",
            "[10] Validation Loss: 3.2815, Accuracy: 22.2973%\n",
            "Train Epoch: 11 [0/74]\tloss: 3.245366\n",
            "Train Epoch: 11 [10/74]\tloss: 3.110714\n",
            "Train Epoch: 11 [20/74]\tloss: 3.120345\n",
            "Train Epoch: 11 [30/74]\tloss: 3.061522\n",
            "Train Epoch: 11 [40/74]\tloss: 3.194821\n",
            "Train Epoch: 11 [50/74]\tloss: 3.111308\n",
            "Train Epoch: 11 [60/74]\tloss: 3.187305\n",
            "Train Epoch: 11 [70/74]\tloss: 2.935305\n",
            "[11] Validation Loss: 3.1532, Accuracy: 26.0135%\n",
            "Train Epoch: 12 [0/74]\tloss: 2.900536\n",
            "Train Epoch: 12 [10/74]\tloss: 2.779618\n",
            "Train Epoch: 12 [20/74]\tloss: 2.798861\n",
            "Train Epoch: 12 [30/74]\tloss: 2.922122\n",
            "Train Epoch: 12 [40/74]\tloss: 2.862664\n",
            "Train Epoch: 12 [50/74]\tloss: 2.977470\n",
            "Train Epoch: 12 [60/74]\tloss: 2.734348\n",
            "Train Epoch: 12 [70/74]\tloss: 3.035012\n",
            "[12] Validation Loss: 3.0224, Accuracy: 33.1081%\n",
            "Train Epoch: 13 [0/74]\tloss: 2.871979\n",
            "Train Epoch: 13 [10/74]\tloss: 3.074004\n",
            "Train Epoch: 13 [20/74]\tloss: 2.764998\n",
            "Train Epoch: 13 [30/74]\tloss: 2.891958\n",
            "Train Epoch: 13 [40/74]\tloss: 2.567606\n",
            "Train Epoch: 13 [50/74]\tloss: 2.479824\n",
            "Train Epoch: 13 [60/74]\tloss: 2.738123\n",
            "Train Epoch: 13 [70/74]\tloss: 2.665081\n",
            "[13] Validation Loss: 2.8886, Accuracy: 37.1622%\n",
            "Train Epoch: 14 [0/74]\tloss: 2.534917\n",
            "Train Epoch: 14 [10/74]\tloss: 2.502872\n",
            "Train Epoch: 14 [20/74]\tloss: 2.682797\n",
            "Train Epoch: 14 [30/74]\tloss: 2.542794\n",
            "Train Epoch: 14 [40/74]\tloss: 2.764893\n",
            "Train Epoch: 14 [50/74]\tloss: 2.561413\n",
            "Train Epoch: 14 [60/74]\tloss: 2.641959\n",
            "Train Epoch: 14 [70/74]\tloss: 2.334134\n",
            "[14] Validation Loss: 2.7512, Accuracy: 45.6081%\n",
            "Train Epoch: 15 [0/74]\tloss: 2.519567\n",
            "Train Epoch: 15 [10/74]\tloss: 2.539768\n",
            "Train Epoch: 15 [20/74]\tloss: 2.452793\n",
            "Train Epoch: 15 [30/74]\tloss: 2.401514\n",
            "Train Epoch: 15 [40/74]\tloss: 2.344546\n",
            "Train Epoch: 15 [50/74]\tloss: 2.308961\n",
            "Train Epoch: 15 [60/74]\tloss: 2.558302\n",
            "Train Epoch: 15 [70/74]\tloss: 2.315272\n",
            "[15] Validation Loss: 2.5965, Accuracy: 48.6486%\n",
            "Train Epoch: 16 [0/74]\tloss: 2.301008\n",
            "Train Epoch: 16 [10/74]\tloss: 2.256690\n",
            "Train Epoch: 16 [20/74]\tloss: 2.279931\n",
            "Train Epoch: 16 [30/74]\tloss: 2.184400\n",
            "Train Epoch: 16 [40/74]\tloss: 2.419789\n",
            "Train Epoch: 16 [50/74]\tloss: 2.469776\n",
            "Train Epoch: 16 [60/74]\tloss: 2.254619\n",
            "Train Epoch: 16 [70/74]\tloss: 2.254935\n",
            "[16] Validation Loss: 2.4599, Accuracy: 53.3784%\n",
            "Train Epoch: 17 [0/74]\tloss: 2.136748\n",
            "Train Epoch: 17 [10/74]\tloss: 2.158328\n",
            "Train Epoch: 17 [20/74]\tloss: 2.213143\n",
            "Train Epoch: 17 [30/74]\tloss: 2.166265\n",
            "Train Epoch: 17 [40/74]\tloss: 2.198699\n",
            "Train Epoch: 17 [50/74]\tloss: 2.044156\n",
            "Train Epoch: 17 [60/74]\tloss: 2.185473\n",
            "Train Epoch: 17 [70/74]\tloss: 2.077506\n",
            "[17] Validation Loss: 2.3209, Accuracy: 56.4189%\n",
            "Train Epoch: 18 [0/74]\tloss: 1.961406\n",
            "Train Epoch: 18 [10/74]\tloss: 2.068983\n",
            "Train Epoch: 18 [20/74]\tloss: 1.887973\n",
            "Train Epoch: 18 [30/74]\tloss: 2.034837\n",
            "Train Epoch: 18 [40/74]\tloss: 2.064371\n",
            "Train Epoch: 18 [50/74]\tloss: 1.938478\n",
            "Train Epoch: 18 [60/74]\tloss: 1.831311\n",
            "Train Epoch: 18 [70/74]\tloss: 1.882437\n",
            "[18] Validation Loss: 2.2023, Accuracy: 61.8243%\n",
            "Train Epoch: 19 [0/74]\tloss: 1.792876\n",
            "Train Epoch: 19 [10/74]\tloss: 1.861980\n",
            "Train Epoch: 19 [20/74]\tloss: 1.768590\n",
            "Train Epoch: 19 [30/74]\tloss: 1.871619\n",
            "Train Epoch: 19 [40/74]\tloss: 1.906052\n",
            "Train Epoch: 19 [50/74]\tloss: 1.724019\n",
            "Train Epoch: 19 [60/74]\tloss: 1.776804\n",
            "Train Epoch: 19 [70/74]\tloss: 1.755564\n",
            "[19] Validation Loss: 2.0808, Accuracy: 63.5135%\n",
            "Train Epoch: 20 [0/74]\tloss: 1.547987\n",
            "Train Epoch: 20 [10/74]\tloss: 1.651749\n",
            "Train Epoch: 20 [20/74]\tloss: 1.642204\n",
            "Train Epoch: 20 [30/74]\tloss: 1.645807\n",
            "Train Epoch: 20 [40/74]\tloss: 1.662975\n",
            "Train Epoch: 20 [50/74]\tloss: 1.811788\n",
            "Train Epoch: 20 [60/74]\tloss: 1.781173\n",
            "Train Epoch: 20 [70/74]\tloss: 1.469009\n",
            "[20] Validation Loss: 1.9889, Accuracy: 67.2297%\n",
            "Train Epoch: 21 [0/74]\tloss: 1.693672\n",
            "Train Epoch: 21 [10/74]\tloss: 1.597850\n",
            "Train Epoch: 21 [20/74]\tloss: 1.451750\n",
            "Train Epoch: 21 [30/74]\tloss: 1.415977\n",
            "Train Epoch: 21 [40/74]\tloss: 1.595890\n",
            "Train Epoch: 21 [50/74]\tloss: 1.477916\n",
            "Train Epoch: 21 [60/74]\tloss: 1.378568\n",
            "Train Epoch: 21 [70/74]\tloss: 1.307388\n",
            "[21] Validation Loss: 1.8708, Accuracy: 69.9324%\n",
            "Train Epoch: 22 [0/74]\tloss: 1.614254\n",
            "Train Epoch: 22 [10/74]\tloss: 1.400799\n",
            "Train Epoch: 22 [20/74]\tloss: 1.388461\n",
            "Train Epoch: 22 [30/74]\tloss: 1.639465\n",
            "Train Epoch: 22 [40/74]\tloss: 1.394117\n",
            "Train Epoch: 22 [50/74]\tloss: 1.422283\n",
            "Train Epoch: 22 [60/74]\tloss: 1.573525\n",
            "Train Epoch: 22 [70/74]\tloss: 1.424505\n",
            "[22] Validation Loss: 1.7732, Accuracy: 73.3108%\n",
            "Train Epoch: 23 [0/74]\tloss: 1.293052\n",
            "Train Epoch: 23 [10/74]\tloss: 1.380385\n",
            "Train Epoch: 23 [20/74]\tloss: 1.275727\n",
            "Train Epoch: 23 [30/74]\tloss: 1.387337\n",
            "Train Epoch: 23 [40/74]\tloss: 1.335475\n",
            "Train Epoch: 23 [50/74]\tloss: 1.181858\n",
            "Train Epoch: 23 [60/74]\tloss: 1.309563\n",
            "Train Epoch: 23 [70/74]\tloss: 1.318628\n",
            "[23] Validation Loss: 1.6760, Accuracy: 74.3243%\n",
            "Train Epoch: 24 [0/74]\tloss: 1.257404\n",
            "Train Epoch: 24 [10/74]\tloss: 1.145347\n",
            "Train Epoch: 24 [20/74]\tloss: 1.441792\n",
            "Train Epoch: 24 [30/74]\tloss: 1.088928\n",
            "Train Epoch: 24 [40/74]\tloss: 1.329917\n",
            "Train Epoch: 24 [50/74]\tloss: 1.186575\n",
            "Train Epoch: 24 [60/74]\tloss: 1.072218\n",
            "Train Epoch: 24 [70/74]\tloss: 1.121857\n",
            "[24] Validation Loss: 1.5658, Accuracy: 76.0135%\n",
            "[FINAL] Test Loss: 1.5924, Accuracy: 78.5235%\n",
            "Best Accuracy:  76.01351351351352\n",
            "Elapsed Time: 0h, 29m, 22s\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██</td></tr><tr><td>Test Accuracy</td><td>▁</td></tr><tr><td>Test Loss</td><td>▁</td></tr><tr><td>Train Loss</td><td>█████▇▇▇▇▆▆▆▅▅▄▄▄▃▃▃▂▂▂▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▁▁▁▁▁▂▂▂▂▃▃▄▄▅▅▆▆▇▇▇▇███</td></tr><tr><td>Validation Loss</td><td>█████▇▇▇▇▆▆▅▅▅▄▄▄▃▃▂▂▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>24</td></tr><tr><td>Test Accuracy</td><td>78.52349</td></tr><tr><td>Test Loss</td><td>1.59237</td></tr><tr><td>Train Loss</td><td>1.18749</td></tr><tr><td>Validation Accuracy</td><td>76.01351</td></tr><tr><td>Validation Loss</td><td>1.56577</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">AdamP_with_get_cosine_schedule</strong> at: <a href='https://wandb.ai/parkdoi-gachon-university/CUB_Transfer_Learning/runs/1rnukd12' target=\"_blank\">https://wandb.ai/parkdoi-gachon-university/CUB_Transfer_Learning/runs/1rnukd12</a><br/> View project at: <a href='https://wandb.ai/parkdoi-gachon-university/CUB_Transfer_Learning' target=\"_blank\">https://wandb.ai/parkdoi-gachon-university/CUB_Transfer_Learning</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20241025_135702-1rnukd12/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}