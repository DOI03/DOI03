{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DOI03/DOI03/blob/main/CV_AL_test11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   optimizer로 AdamP 사용\n",
        "2.   lr = 0.0001\n",
        "3.   CosineAnnealingLR 스케줄러 사용\n",
        "4.   data augmentation 으로\n",
        "     Geometric transformation & visual corruptions\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "JBBnibyCbQ_A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xr4ox9es1m_Z",
        "outputId": "9ef4e566-9fd1-4ab6-d81f-57737d511e9e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb\n",
        "!pip install adamp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7a36Uzf7yL9l",
        "outputId": "d6850566-0c2d-42e4-da56-5b5c42c09111"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.18.5)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.43)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.17.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (75.1.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.10/dist-packages (from wandb) (4.12.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.8.30)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n",
            "Collecting adamp\n",
            "  Downloading adamp-0.3.0.tar.gz (5.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: adamp\n",
            "  Building wheel for adamp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for adamp: filename=adamp-0.3.0-py3-none-any.whl size=5984 sha256=2816d8a5e13f5cd74bcee5724f4821a4afc5a6fdb951daf3a781e8d823468b2f\n",
            "  Stored in directory: /root/.cache/pip/wheels/c7/ad/0f/b41b1c45b18c66e5eef5d2254415af8055c7e2b0934145157d\n",
            "Successfully built adamp\n",
            "Installing collected packages: adamp\n",
            "Successfully installed adamp-0.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "qOc0tT3-nv73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "75c86149-69d4-4120-e32a-097cc4748000"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.18.5"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241025_133149-ljhwewsw</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/parkdoi-gachon-university/CUB_Transfer_Learning/runs/ljhwewsw' target=\"_blank\">AdamP and CosineAnnealingLR_with augmentation</a></strong> to <a href='https://wandb.ai/parkdoi-gachon-university/CUB_Transfer_Learning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/parkdoi-gachon-university/CUB_Transfer_Learning' target=\"_blank\">https://wandb.ai/parkdoi-gachon-university/CUB_Transfer_Learning</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/parkdoi-gachon-university/CUB_Transfer_Learning/runs/ljhwewsw' target=\"_blank\">https://wandb.ai/parkdoi-gachon-university/CUB_Transfer_Learning/runs/ljhwewsw</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import time\n",
        "\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import wandb\n",
        "\n",
        "# adamp 사용\n",
        "from adamp import AdamP\n",
        "\n",
        "# 스케줄러 사용\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "\n",
        "from PIL import Image\n",
        "#내가 추가\n",
        "import re\n",
        "\n",
        "# wandb 설정 (오프라인 모드로 실행)\n",
        "wandb.init(project=\"CUB_Transfer_Learning\", name=\"AdamP and CosineAnnealingLR_with augmentation\")\n",
        "\n",
        "### GPU Setting ###\n",
        "USE_CUDA = torch.cuda.is_available()\n",
        "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
        "print(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Custom Dataset ###\n",
        "class CUB2011(Dataset):\n",
        "  def __init__(self, transform, mode='train'):\n",
        "    self.transform = transform\n",
        "    self.mode = mode\n",
        "\n",
        "    if self.mode == 'train':\n",
        "      self.image_folder = os.listdir('/content/gdrive/MyDrive/CUB_200_2011_repackage_class50/datasets/train')\n",
        "    elif self.mode == 'valid':\n",
        "      self.image_folder = os.listdir('/content/gdrive/MyDrive/CUB_200_2011_repackage_class50/datasets/valid')\n",
        "    elif self.mode == 'test':\n",
        "      self.image_folder = os.listdir('/content/gdrive/MyDrive/CUB_200_2011_repackage_class50/datasets/test')\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.image_folder)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    img_path = self.image_folder[idx]\n",
        "    img = Image.open(os.path.join('/content/gdrive/MyDrive/CUB_200_2011_repackage_class50/datasets', self.mode, img_path)).convert('RGB')\n",
        "    img = self.transform(img)\n",
        "    label = img_path.split('_')[-1].split('.')[0]\n",
        "    label = re.sub(r'\\([^)]*\\)', '', label)\n",
        "    label = int(label)\n",
        "    return (img, label)"
      ],
      "metadata": {
        "id": "KaFgjkFp8tzI"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Data Preprocessing ###\n",
        "\n",
        "# 학습 데이터에 Geometric Transformations 및 Visual Corruptions 추가\n",
        "transforms_train = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(448),  # Geometric Transformation: Random crop\n",
        "    transforms.RandomHorizontalFlip(),  # Geometric Transformation: Random horizontal flip\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Visual Corruption: Color jitter\n",
        "    transforms.GaussianBlur(3, sigma=(0.1, 2.0)),  # Visual Corruption: Gaussian blur\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# 검증 및 테스트 데이터는 최소한의 변형만 적용\n",
        "transforms_valtest = transforms.Compose([\n",
        "    transforms.Resize((448, 448)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "train_set = CUB2011(mode='train',\n",
        "                    transform=transforms_train)\n",
        "val_set = CUB2011(mode='valid',\n",
        "                  transform=transforms_valtest)\n",
        "test_set = CUB2011(mode='test',\n",
        "                  transform=transforms_valtest)\n",
        "\n",
        "print('Num of each dataset: ', len(train_set), len(val_set), len(test_set))\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_set, batch_size=BATCH_SIZE, shuffle=False)\n",
        "test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "print(\"Loaded dataloader\")\n",
        "\n",
        "### Model / Optimizer ###\n",
        "EPOCH = 25\n",
        "lr = 0.0001\n",
        "\n",
        "model = models.resnet18(pretrained=True)\n",
        "\n",
        "### Transfer Learning ###\n",
        "num_features = model.fc.in_features\n",
        "model.fc = nn.Linear(num_features, 50)\n",
        "model.to(DEVICE)\n",
        "\n",
        "optimizer = optim.RAdam(model.parameters(), lr=lr)\n",
        "\n",
        "# 스케줄러 초기화 (주기와 최소/최대 학습률 설정)\n",
        "scheduler = CosineAnnealingLR(optimizer, T_max=15, eta_min=0.001)\n",
        "\n",
        "print(\"Created a learning model and optimizer\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38vx5jj22neg",
        "outputId": "197b2d4d-c0b1-472b-f16a-2dcc80687bb9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num of each dataset:  2360 296 298\n",
            "Loaded dataloader\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 111MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created a learning model and optimizer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Train/Evaluation ###\n",
        "def train(model,train_loader,optimizer,epoch):\n",
        "  model.train()\n",
        "  for i,(image,target) in enumerate(train_loader):\n",
        "    image,target = image.to(DEVICE),target.to(DEVICE)\n",
        "    output = model(image)\n",
        "    optimizer.zero_grad()\n",
        "    train_loss = F.cross_entropy(output,target).to(DEVICE)\n",
        "\n",
        "    train_loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # 스케줄러 업데이트\n",
        "    scheduler.step()\n",
        "\n",
        "    if i%10 ==0:\n",
        "      print(\n",
        "          f'Train Epoch: {epoch} [{i}/{len(train_loader)}]\\tloss: {train_loss.item():6f}')\n",
        "\n",
        "  return train_loss\n",
        "\n",
        "def evaluate(model,val_loader):\n",
        "  model.eval()\n",
        "  eval_loss = 0\n",
        "  correct = 0\n",
        "  with torch.no_grad():\n",
        "    for i,(image,target) in enumerate(val_loader):\n",
        "      image,target = image.to(DEVICE),target.to(DEVICE)\n",
        "      output = model(image)\n",
        "\n",
        "      eval_loss += F.cross_entropy(output,target, reduction='sum').item()\n",
        "      pred = output.max(1,keepdim=True)[1]\n",
        "      correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "  eval_loss /= len(val_loader.dataset)\n",
        "  eval_accuracy = 100*correct / len(val_loader.dataset)\n",
        "  return eval_loss,eval_accuracy"
      ],
      "metadata": {
        "id": "apDhVk6C2r7R"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Main ###\n",
        "start = time.time()\n",
        "best = 0\n",
        "for epoch in range(EPOCH):\n",
        "    train_loss = train(model, train_loader, optimizer, epoch)\n",
        "    val_loss, val_accuracy = evaluate(model, val_loader)\n",
        "\n",
        "    # wandb 로그 기록\n",
        "    wandb.log({\n",
        "        'Epoch': epoch,\n",
        "        'Train Loss': train_loss,\n",
        "        'Validation Loss': val_loss,\n",
        "        'Validation Accuracy': val_accuracy\n",
        "    })\n",
        "\n",
        "    # Save best model\n",
        "    if val_accuracy > best:\n",
        "        best = val_accuracy\n",
        "        torch.save(model.state_dict(), \"./best_model.pth\")\n",
        "\n",
        "    print(f\"[{epoch}] Validation Loss: {val_loss:.4f}, Accuracy: {val_accuracy:.4f}%\")\n",
        "\n",
        "# Test result\n",
        "test_loss, test_accuracy = evaluate(model, test_loader)\n",
        "print(f'[FINAL] Test Loss: {test_loss:.4f}, Accuracy: {test_accuracy:.4f}%')\n",
        "\n",
        "# wandb 테스트 결과 로그 기록\n",
        "wandb.log({\n",
        "    'Test Loss': test_loss,\n",
        "    'Test Accuracy': test_accuracy\n",
        "})\n",
        "\n",
        "end = time.time()\n",
        "elapsed_time = end - start\n",
        "\n",
        "print(\"Best Accuracy: \", best)\n",
        "print(f\"Elapsed Time: {int(elapsed_time / 3600)}h, {int(elapsed_time / 60)}m, {int(elapsed_time % 60)}s\")\n",
        "\n",
        "wandb.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VNhSTX452wyd",
        "outputId": "ebf1fc4c-9ac8-4305-c763-90e33cda444f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 0 [0/74]\tloss: 4.020966\n",
            "Train Epoch: 0 [10/74]\tloss: 4.030453\n",
            "Train Epoch: 0 [20/74]\tloss: 3.881047\n",
            "Train Epoch: 0 [30/74]\tloss: 3.749581\n",
            "Train Epoch: 0 [40/74]\tloss: 3.577199\n",
            "Train Epoch: 0 [50/74]\tloss: 3.402426\n",
            "Train Epoch: 0 [60/74]\tloss: 3.426679\n",
            "Train Epoch: 0 [70/74]\tloss: 3.150295\n",
            "[0] Validation Loss: 3.0047, Accuracy: 26.0135%\n",
            "Train Epoch: 1 [0/74]\tloss: 3.054127\n",
            "Train Epoch: 1 [10/74]\tloss: 2.827568\n",
            "Train Epoch: 1 [20/74]\tloss: 2.832252\n",
            "Train Epoch: 1 [30/74]\tloss: 2.792326\n",
            "Train Epoch: 1 [40/74]\tloss: 2.584912\n",
            "Train Epoch: 1 [50/74]\tloss: 2.675584\n",
            "Train Epoch: 1 [60/74]\tloss: 2.587312\n",
            "Train Epoch: 1 [70/74]\tloss: 2.181275\n",
            "[1] Validation Loss: 1.9454, Accuracy: 58.4459%\n",
            "Train Epoch: 2 [0/74]\tloss: 2.248001\n",
            "Train Epoch: 2 [10/74]\tloss: 1.829020\n",
            "Train Epoch: 2 [20/74]\tloss: 2.138807\n",
            "Train Epoch: 2 [30/74]\tloss: 1.766723\n",
            "Train Epoch: 2 [40/74]\tloss: 1.940015\n",
            "Train Epoch: 2 [50/74]\tloss: 1.806032\n",
            "Train Epoch: 2 [60/74]\tloss: 2.030654\n",
            "Train Epoch: 2 [70/74]\tloss: 1.748561\n",
            "[2] Validation Loss: 1.3797, Accuracy: 68.5811%\n",
            "Train Epoch: 3 [0/74]\tloss: 1.546520\n",
            "Train Epoch: 3 [10/74]\tloss: 1.741172\n",
            "Train Epoch: 3 [20/74]\tloss: 1.342306\n",
            "Train Epoch: 3 [30/74]\tloss: 1.256468\n",
            "Train Epoch: 3 [40/74]\tloss: 1.667334\n",
            "Train Epoch: 3 [50/74]\tloss: 1.148463\n",
            "Train Epoch: 3 [60/74]\tloss: 1.454666\n",
            "Train Epoch: 3 [70/74]\tloss: 1.359235\n",
            "[3] Validation Loss: 1.3377, Accuracy: 68.5811%\n",
            "Train Epoch: 4 [0/74]\tloss: 1.410743\n",
            "Train Epoch: 4 [10/74]\tloss: 1.266289\n",
            "Train Epoch: 4 [20/74]\tloss: 1.076803\n",
            "Train Epoch: 4 [30/74]\tloss: 0.912206\n",
            "Train Epoch: 4 [40/74]\tloss: 1.166107\n",
            "Train Epoch: 4 [50/74]\tloss: 1.167361\n",
            "Train Epoch: 4 [60/74]\tloss: 1.355409\n",
            "Train Epoch: 4 [70/74]\tloss: 1.113447\n",
            "[4] Validation Loss: 1.0760, Accuracy: 80.4054%\n",
            "Train Epoch: 5 [0/74]\tloss: 1.047288\n",
            "Train Epoch: 5 [10/74]\tloss: 1.249185\n",
            "Train Epoch: 5 [20/74]\tloss: 1.048996\n",
            "Train Epoch: 5 [30/74]\tloss: 0.930273\n",
            "Train Epoch: 5 [40/74]\tloss: 1.533911\n",
            "Train Epoch: 5 [50/74]\tloss: 1.133254\n",
            "Train Epoch: 5 [60/74]\tloss: 1.272020\n",
            "Train Epoch: 5 [70/74]\tloss: 1.079449\n",
            "[5] Validation Loss: 0.9879, Accuracy: 79.0541%\n",
            "Train Epoch: 6 [0/74]\tloss: 0.962259\n",
            "Train Epoch: 6 [10/74]\tloss: 1.209751\n",
            "Train Epoch: 6 [20/74]\tloss: 1.044977\n",
            "Train Epoch: 6 [30/74]\tloss: 0.849956\n",
            "Train Epoch: 6 [40/74]\tloss: 1.033665\n",
            "Train Epoch: 6 [50/74]\tloss: 0.728689\n",
            "Train Epoch: 6 [60/74]\tloss: 0.817555\n",
            "Train Epoch: 6 [70/74]\tloss: 0.919201\n",
            "[6] Validation Loss: 0.7791, Accuracy: 83.4459%\n",
            "Train Epoch: 7 [0/74]\tloss: 0.967176\n",
            "Train Epoch: 7 [10/74]\tloss: 0.833999\n",
            "Train Epoch: 7 [20/74]\tloss: 1.200585\n",
            "Train Epoch: 7 [30/74]\tloss: 1.038884\n",
            "Train Epoch: 7 [40/74]\tloss: 0.850783\n",
            "Train Epoch: 7 [50/74]\tloss: 1.290485\n",
            "Train Epoch: 7 [60/74]\tloss: 0.704554\n",
            "Train Epoch: 7 [70/74]\tloss: 0.857247\n",
            "[7] Validation Loss: 1.1476, Accuracy: 68.9189%\n",
            "Train Epoch: 8 [0/74]\tloss: 0.905862\n",
            "Train Epoch: 8 [10/74]\tloss: 0.821475\n",
            "Train Epoch: 8 [20/74]\tloss: 0.715345\n",
            "Train Epoch: 8 [30/74]\tloss: 1.042689\n",
            "Train Epoch: 8 [40/74]\tloss: 0.622245\n",
            "Train Epoch: 8 [50/74]\tloss: 0.661266\n",
            "Train Epoch: 8 [60/74]\tloss: 0.858627\n",
            "Train Epoch: 8 [70/74]\tloss: 0.846722\n",
            "[8] Validation Loss: 0.7065, Accuracy: 84.1216%\n",
            "Train Epoch: 9 [0/74]\tloss: 0.600224\n",
            "Train Epoch: 9 [10/74]\tloss: 0.656888\n",
            "Train Epoch: 9 [20/74]\tloss: 0.804263\n",
            "Train Epoch: 9 [30/74]\tloss: 0.514314\n",
            "Train Epoch: 9 [40/74]\tloss: 0.555635\n",
            "Train Epoch: 9 [50/74]\tloss: 0.753630\n",
            "Train Epoch: 9 [60/74]\tloss: 0.761235\n",
            "Train Epoch: 9 [70/74]\tloss: 0.484466\n",
            "[9] Validation Loss: 1.2748, Accuracy: 65.5405%\n",
            "Train Epoch: 10 [0/74]\tloss: 0.715105\n",
            "Train Epoch: 10 [10/74]\tloss: 0.716407\n",
            "Train Epoch: 10 [20/74]\tloss: 0.545645\n",
            "Train Epoch: 10 [30/74]\tloss: 1.088267\n",
            "Train Epoch: 10 [40/74]\tloss: 0.678846\n",
            "Train Epoch: 10 [50/74]\tloss: 0.958197\n",
            "Train Epoch: 10 [60/74]\tloss: 0.679283\n",
            "Train Epoch: 10 [70/74]\tloss: 0.780802\n",
            "[10] Validation Loss: 0.7412, Accuracy: 80.4054%\n",
            "Train Epoch: 11 [0/74]\tloss: 0.713951\n",
            "Train Epoch: 11 [10/74]\tloss: 0.931740\n",
            "Train Epoch: 11 [20/74]\tloss: 0.895408\n",
            "Train Epoch: 11 [30/74]\tloss: 0.594106\n",
            "Train Epoch: 11 [40/74]\tloss: 0.541070\n",
            "Train Epoch: 11 [50/74]\tloss: 1.021297\n",
            "Train Epoch: 11 [60/74]\tloss: 0.485786\n",
            "Train Epoch: 11 [70/74]\tloss: 0.610122\n",
            "[11] Validation Loss: 0.8939, Accuracy: 76.3514%\n",
            "Train Epoch: 12 [0/74]\tloss: 0.677544\n",
            "Train Epoch: 12 [10/74]\tloss: 0.615212\n",
            "Train Epoch: 12 [20/74]\tloss: 0.744975\n",
            "Train Epoch: 12 [30/74]\tloss: 0.816139\n",
            "Train Epoch: 12 [40/74]\tloss: 0.912777\n",
            "Train Epoch: 12 [50/74]\tloss: 0.552300\n",
            "Train Epoch: 12 [60/74]\tloss: 1.133675\n",
            "Train Epoch: 12 [70/74]\tloss: 0.695456\n",
            "[12] Validation Loss: 0.7666, Accuracy: 82.7703%\n",
            "Train Epoch: 13 [0/74]\tloss: 0.816975\n",
            "Train Epoch: 13 [10/74]\tloss: 0.483734\n",
            "Train Epoch: 13 [20/74]\tloss: 0.937898\n",
            "Train Epoch: 13 [30/74]\tloss: 0.728516\n",
            "Train Epoch: 13 [40/74]\tloss: 0.663376\n",
            "Train Epoch: 13 [50/74]\tloss: 0.763678\n",
            "Train Epoch: 13 [60/74]\tloss: 0.929763\n",
            "Train Epoch: 13 [70/74]\tloss: 0.550356\n",
            "[13] Validation Loss: 0.9784, Accuracy: 78.3784%\n",
            "Train Epoch: 14 [0/74]\tloss: 0.485320\n",
            "Train Epoch: 14 [10/74]\tloss: 0.923720\n",
            "Train Epoch: 14 [20/74]\tloss: 0.519149\n",
            "Train Epoch: 14 [30/74]\tloss: 0.538907\n",
            "Train Epoch: 14 [40/74]\tloss: 0.847768\n",
            "Train Epoch: 14 [50/74]\tloss: 0.635992\n",
            "Train Epoch: 14 [60/74]\tloss: 0.878892\n",
            "Train Epoch: 14 [70/74]\tloss: 0.450138\n",
            "[14] Validation Loss: 0.8203, Accuracy: 77.0270%\n",
            "Train Epoch: 15 [0/74]\tloss: 0.523335\n",
            "Train Epoch: 15 [10/74]\tloss: 0.376602\n",
            "Train Epoch: 15 [20/74]\tloss: 0.617983\n",
            "Train Epoch: 15 [30/74]\tloss: 1.166389\n",
            "Train Epoch: 15 [40/74]\tloss: 0.847184\n",
            "Train Epoch: 15 [50/74]\tloss: 0.783608\n",
            "Train Epoch: 15 [60/74]\tloss: 0.567029\n",
            "Train Epoch: 15 [70/74]\tloss: 0.517508\n",
            "[15] Validation Loss: 1.0589, Accuracy: 73.3108%\n",
            "Train Epoch: 16 [0/74]\tloss: 0.592874\n",
            "Train Epoch: 16 [10/74]\tloss: 0.695129\n",
            "Train Epoch: 16 [20/74]\tloss: 0.615193\n",
            "Train Epoch: 16 [30/74]\tloss: 0.265458\n",
            "Train Epoch: 16 [40/74]\tloss: 0.808682\n",
            "Train Epoch: 16 [50/74]\tloss: 0.797957\n",
            "Train Epoch: 16 [60/74]\tloss: 0.652060\n",
            "Train Epoch: 16 [70/74]\tloss: 0.744215\n",
            "[16] Validation Loss: 0.8639, Accuracy: 76.3514%\n",
            "Train Epoch: 17 [0/74]\tloss: 0.785613\n",
            "Train Epoch: 17 [10/74]\tloss: 0.641629\n",
            "Train Epoch: 17 [20/74]\tloss: 0.810345\n",
            "Train Epoch: 17 [30/74]\tloss: 1.184634\n",
            "Train Epoch: 17 [40/74]\tloss: 0.605579\n",
            "Train Epoch: 17 [50/74]\tloss: 0.584186\n",
            "Train Epoch: 17 [60/74]\tloss: 0.440266\n",
            "Train Epoch: 17 [70/74]\tloss: 0.495852\n",
            "[17] Validation Loss: 0.6921, Accuracy: 82.7703%\n",
            "Train Epoch: 18 [0/74]\tloss: 0.358882\n",
            "Train Epoch: 18 [10/74]\tloss: 0.432338\n",
            "Train Epoch: 18 [20/74]\tloss: 0.756728\n",
            "Train Epoch: 18 [30/74]\tloss: 0.595641\n",
            "Train Epoch: 18 [40/74]\tloss: 0.224151\n",
            "Train Epoch: 18 [50/74]\tloss: 0.644652\n",
            "Train Epoch: 18 [60/74]\tloss: 0.387515\n",
            "Train Epoch: 18 [70/74]\tloss: 1.355904\n",
            "[18] Validation Loss: 1.1231, Accuracy: 73.6486%\n",
            "Train Epoch: 19 [0/74]\tloss: 0.341358\n",
            "Train Epoch: 19 [10/74]\tloss: 0.715029\n",
            "Train Epoch: 19 [20/74]\tloss: 0.515412\n",
            "Train Epoch: 19 [30/74]\tloss: 0.911053\n",
            "Train Epoch: 19 [40/74]\tloss: 0.435103\n",
            "Train Epoch: 19 [50/74]\tloss: 0.979249\n",
            "Train Epoch: 19 [60/74]\tloss: 0.817650\n",
            "Train Epoch: 19 [70/74]\tloss: 0.833807\n",
            "[19] Validation Loss: 0.8651, Accuracy: 76.0135%\n",
            "Train Epoch: 20 [0/74]\tloss: 0.314219\n",
            "Train Epoch: 20 [10/74]\tloss: 0.842299\n",
            "Train Epoch: 20 [20/74]\tloss: 0.403493\n",
            "Train Epoch: 20 [30/74]\tloss: 0.771270\n",
            "Train Epoch: 20 [40/74]\tloss: 0.588961\n",
            "Train Epoch: 20 [50/74]\tloss: 0.776726\n",
            "Train Epoch: 20 [60/74]\tloss: 0.476685\n",
            "Train Epoch: 20 [70/74]\tloss: 0.971572\n",
            "[20] Validation Loss: 0.9603, Accuracy: 74.3243%\n",
            "Train Epoch: 21 [0/74]\tloss: 0.624004\n",
            "Train Epoch: 21 [10/74]\tloss: 0.233963\n",
            "Train Epoch: 21 [20/74]\tloss: 0.386678\n",
            "Train Epoch: 21 [30/74]\tloss: 0.656792\n",
            "Train Epoch: 21 [40/74]\tloss: 0.470134\n",
            "Train Epoch: 21 [50/74]\tloss: 0.483404\n",
            "Train Epoch: 21 [60/74]\tloss: 0.505691\n",
            "Train Epoch: 21 [70/74]\tloss: 0.684357\n",
            "[21] Validation Loss: 0.6684, Accuracy: 82.7703%\n",
            "Train Epoch: 22 [0/74]\tloss: 0.650947\n",
            "Train Epoch: 22 [10/74]\tloss: 0.525519\n",
            "Train Epoch: 22 [20/74]\tloss: 0.696421\n",
            "Train Epoch: 22 [30/74]\tloss: 0.576517\n",
            "Train Epoch: 22 [40/74]\tloss: 0.465580\n",
            "Train Epoch: 22 [50/74]\tloss: 0.472465\n",
            "Train Epoch: 22 [60/74]\tloss: 0.626043\n",
            "Train Epoch: 22 [70/74]\tloss: 0.708117\n",
            "[22] Validation Loss: 1.3503, Accuracy: 68.2432%\n",
            "Train Epoch: 23 [0/74]\tloss: 0.777910\n",
            "Train Epoch: 23 [10/74]\tloss: 0.499832\n",
            "Train Epoch: 23 [20/74]\tloss: 0.629985\n",
            "Train Epoch: 23 [30/74]\tloss: 1.267979\n",
            "Train Epoch: 23 [40/74]\tloss: 0.387158\n",
            "Train Epoch: 23 [50/74]\tloss: 0.240303\n",
            "Train Epoch: 23 [60/74]\tloss: 0.625854\n",
            "Train Epoch: 23 [70/74]\tloss: 0.644959\n",
            "[23] Validation Loss: 0.5616, Accuracy: 85.8108%\n",
            "Train Epoch: 24 [0/74]\tloss: 0.602177\n",
            "Train Epoch: 24 [10/74]\tloss: 0.701342\n",
            "Train Epoch: 24 [20/74]\tloss: 0.367826\n",
            "Train Epoch: 24 [30/74]\tloss: 0.670732\n",
            "Train Epoch: 24 [40/74]\tloss: 0.338295\n",
            "Train Epoch: 24 [50/74]\tloss: 0.439653\n",
            "Train Epoch: 24 [60/74]\tloss: 0.555173\n",
            "Train Epoch: 24 [70/74]\tloss: 0.846314\n",
            "[24] Validation Loss: 1.1368, Accuracy: 69.2568%\n",
            "[FINAL] Test Loss: 1.1347, Accuracy: 72.4832%\n",
            "Best Accuracy:  85.8108108108108\n",
            "Elapsed Time: 0h, 52m, 23s\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██</td></tr><tr><td>Test Accuracy</td><td>▁</td></tr><tr><td>Test Loss</td><td>▁</td></tr><tr><td>Train Loss</td><td>█▅▄▄▄▄▃▃▂▃▂▁▃▂▂▁▃▁▃▃▂▂▂▂▂</td></tr><tr><td>Validation Accuracy</td><td>▁▅▆▆▇▇█▆█▆▇▇█▇▇▇▇█▇▇▇█▆█▆</td></tr><tr><td>Validation Loss</td><td>█▅▃▃▂▂▂▃▁▃▂▂▂▂▂▂▂▁▃▂▂▁▃▁▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>24</td></tr><tr><td>Test Accuracy</td><td>72.48322</td></tr><tr><td>Test Loss</td><td>1.13472</td></tr><tr><td>Train Loss</td><td>0.65904</td></tr><tr><td>Validation Accuracy</td><td>69.25676</td></tr><tr><td>Validation Loss</td><td>1.13675</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">AdamP and CosineAnnealingLR_with augmentation</strong> at: <a href='https://wandb.ai/parkdoi-gachon-university/CUB_Transfer_Learning/runs/ljhwewsw' target=\"_blank\">https://wandb.ai/parkdoi-gachon-university/CUB_Transfer_Learning/runs/ljhwewsw</a><br/> View project at: <a href='https://wandb.ai/parkdoi-gachon-university/CUB_Transfer_Learning' target=\"_blank\">https://wandb.ai/parkdoi-gachon-university/CUB_Transfer_Learning</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20241025_133149-ljhwewsw/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}