{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DOI03/DOI03/blob/main/CV_AL_test6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   optimizer로 AdamP 사용\n",
        "2.   lr 0.0001\n",
        "3.   epoch 25\n",
        "4.   CosineAnnealingLR 스케줄러 사용\n",
        "\n"
      ],
      "metadata": {
        "id": "JBBnibyCbQ_A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xr4ox9es1m_Z",
        "outputId": "7cdc83c4-bcdd-4226-854b-291ed00e8d0a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb\n",
        "!pip install adamp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7a36Uzf7yL9l",
        "outputId": "6d303166-224a-4821-dfbe-d127f5253ae1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.18.5)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.43)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.17.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (75.1.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.10/dist-packages (from wandb) (4.12.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.8.30)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n",
            "Collecting adamp\n",
            "  Downloading adamp-0.3.0.tar.gz (5.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: adamp\n",
            "  Building wheel for adamp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for adamp: filename=adamp-0.3.0-py3-none-any.whl size=5984 sha256=c74a26841be4a7ede45c86d48a233904b649411b7d098059a23c511542f4d7e1\n",
            "  Stored in directory: /root/.cache/pip/wheels/c7/ad/0f/b41b1c45b18c66e5eef5d2254415af8055c7e2b0934145157d\n",
            "Successfully built adamp\n",
            "Installing collected packages: adamp\n",
            "Successfully installed adamp-0.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "qOc0tT3-nv73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "c6129a45-c028-4ea0-89e2-d90239f7c616"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.18.5"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241025_125619-xxc0q265</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/parkdoi-gachon-university/CUB_Transfer_Learning/runs/xxc0q265' target=\"_blank\">AdamP_with_CosineAnnealingLR</a></strong> to <a href='https://wandb.ai/parkdoi-gachon-university/CUB_Transfer_Learning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/parkdoi-gachon-university/CUB_Transfer_Learning' target=\"_blank\">https://wandb.ai/parkdoi-gachon-university/CUB_Transfer_Learning</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/parkdoi-gachon-university/CUB_Transfer_Learning/runs/xxc0q265' target=\"_blank\">https://wandb.ai/parkdoi-gachon-university/CUB_Transfer_Learning/runs/xxc0q265</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import time\n",
        "\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import wandb\n",
        "\n",
        "# AdamP 사용\n",
        "from adamp import AdamP\n",
        "\n",
        "from PIL import Image\n",
        "#내가 추가\n",
        "import re\n",
        "\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "\n",
        "### wandb 설정 ###\n",
        "wandb.init(project=\"CUB_Transfer_Learning\", name=\"AdamP_with_CosineAnnealingLR\")\n",
        "\n",
        "### GPU Setting ###\n",
        "USE_CUDA = torch.cuda.is_available()\n",
        "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
        "print(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Custom Dataset ###\n",
        "class CUB2011(Dataset):\n",
        "  def __init__(self, transform, mode='train'):\n",
        "    self.transform = transform\n",
        "    self.mode = mode\n",
        "\n",
        "    if self.mode == 'train':\n",
        "      self.image_folder = os.listdir('/content/gdrive/MyDrive/CUB_200_2011_repackage_class50/datasets/train')\n",
        "    elif self.mode == 'valid':\n",
        "      self.image_folder = os.listdir('/content/gdrive/MyDrive/CUB_200_2011_repackage_class50/datasets/valid')\n",
        "    elif self.mode == 'test':\n",
        "      self.image_folder = os.listdir('/content/gdrive/MyDrive/CUB_200_2011_repackage_class50/datasets/test')\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.image_folder)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    img_path = self.image_folder[idx]\n",
        "    img = Image.open(os.path.join('/content/gdrive/MyDrive/CUB_200_2011_repackage_class50/datasets', self.mode, img_path)).convert('RGB')\n",
        "    img = self.transform(img)\n",
        "    label = img_path.split('_')[-1].split('.')[0]\n",
        "    label = re.sub(r'\\([^)]*\\)', '', label)\n",
        "    label = int(label)\n",
        "    return (img, label)"
      ],
      "metadata": {
        "id": "KaFgjkFp8tzI"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Data Preprocessing ###\n",
        "\n",
        "'''\n",
        "# 데이터 정규화 추가\n",
        "# 정규화 변환 정의\n",
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "'''\n",
        "transforms_train = transforms.Compose([transforms.Resize((448,448)),\n",
        "                                       transforms.ToTensor()])\n",
        "transforms_valtest = transforms.Compose([transforms.Resize((448,448)),\n",
        "                                         transforms.ToTensor()])\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "train_set = CUB2011(mode='train',\n",
        "                    transform=transforms_train)\n",
        "# transforms_train을 transforms_valtest로 변경\n",
        "val_set = CUB2011(mode='valid',\n",
        "                  transform=transforms_valtest)\n",
        "test_set = CUB2011(mode='test',\n",
        "                  transform=transforms_valtest)\n",
        "\n",
        "print('Num of each dataset: ',len(train_set),len(val_set),len(test_set))\n",
        "\n",
        "train_loader = DataLoader(train_set,batch_size=BATCH_SIZE,shuffle=True)\n",
        "val_loader = DataLoader(val_set,batch_size=BATCH_SIZE,shuffle=False)\n",
        "test_loader = DataLoader(test_set,batch_size=BATCH_SIZE,shuffle=False)\n",
        "\n",
        "print(\"Loaded dataloader\")\n",
        "\n",
        "### Model / Optimizer ###\n",
        "EPOCH = 25\n",
        "lr = 0.0001\n",
        "\n",
        "model = models.resnet18(pretrained=True)\n",
        "\n",
        "### Tranfer Learning ###\n",
        "num_features = model.fc.in_features\n",
        "model.fc = nn.Linear(num_features,50)\n",
        "model.to(DEVICE)\n",
        "\n",
        "optimizer = AdamP(model.parameters(), lr=lr)\n",
        "scheduler = CosineAnnealingLR(optimizer, T_max=EPOCH)\n",
        "\n",
        "print(\"Created a learning model and optimizer\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38vx5jj22neg",
        "outputId": "714b5eb1-b1cc-4a35-d259-a8f33a82f9e2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num of each dataset:  2360 296 298\n",
            "Loaded dataloader\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 191MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created a learning model and optimizer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Train/Evaluation ###\n",
        "def train(model, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    train_loss_total = 0\n",
        "    for i, (image, target) in enumerate(train_loader):\n",
        "        image, target = image.to(DEVICE), target.to(DEVICE)\n",
        "        output = model(image)\n",
        "        optimizer.zero_grad()\n",
        "        train_loss = F.cross_entropy(output, target).to(DEVICE)\n",
        "\n",
        "        train_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss_total += train_loss.item()\n",
        "\n",
        "        if i % 10 == 0:\n",
        "            print(f'Train Epoch: {epoch} [{i}/{len(train_loader)}]\\tloss: {train_loss.item():.6f}')\n",
        "\n",
        "    avg_train_loss = train_loss_total / len(train_loader)\n",
        "    return avg_train_loss\n",
        "\n",
        "def evaluate(model, val_loader):\n",
        "    model.eval()\n",
        "    eval_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for i, (image, target) in enumerate(val_loader):\n",
        "            image, target = image.to(DEVICE), target.to(DEVICE)\n",
        "            output = model(image)\n",
        "\n",
        "            eval_loss += F.cross_entropy(output, target, reduction='sum').item()\n",
        "            pred = output.max(1, keepdim=True)[1]\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    eval_loss /= len(val_loader.dataset)\n",
        "    eval_accuracy = 100 * correct / len(val_loader.dataset)\n",
        "    return eval_loss, eval_accuracy"
      ],
      "metadata": {
        "id": "apDhVk6C2r7R"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Main ###\n",
        "start = time.time()\n",
        "best = 0\n",
        "for epoch in range(EPOCH):\n",
        "    train_loss = train(model, train_loader, optimizer, epoch)\n",
        "    val_loss, val_accuracy = evaluate(model, val_loader)\n",
        "\n",
        "    # 스케줄러 업데이트 (에포크가 끝난 후)\n",
        "    scheduler.step()\n",
        "\n",
        "    # wandb 로그 기록\n",
        "    wandb.log({\n",
        "        'Epoch': epoch,\n",
        "        'Train Loss': train_loss,\n",
        "        'Validation Loss': val_loss,\n",
        "        'Validation Accuracy': val_accuracy\n",
        "    })\n",
        "\n",
        "    # Save best model\n",
        "    if val_accuracy > best:\n",
        "        best = val_accuracy\n",
        "        torch.save(model.state_dict(), \"./best_model.pth\")\n",
        "\n",
        "    print(f\"[{epoch}] Validation Loss: {val_loss:.4f}, Accuracy: {val_accuracy:.4f}%\")\n",
        "\n",
        "# Test result\n",
        "test_loss, test_accuracy = evaluate(model, test_loader)\n",
        "print(f'[FINAL] Test Loss: {test_loss:.4f}, Accuracy: {test_accuracy:.4f}%')\n",
        "\n",
        "# wandb 테스트 결과 로그 기록\n",
        "wandb.log({\n",
        "    'Test Loss': test_loss,\n",
        "    'Test Accuracy': test_accuracy\n",
        "})\n",
        "\n",
        "end = time.time()\n",
        "elapsed_time = end - start\n",
        "\n",
        "print(\"Best Accuracy: \", best)\n",
        "print(f\"Elapsed Time: {int(elapsed_time / 3600)}h, {int(elapsed_time / 60)}m, {int(elapsed_time % 60)}s\")\n",
        "\n",
        "wandb.finish()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VNhSTX452wyd",
        "outputId": "80daa9c7-6996-409a-b7ef-5bc61c5caa73"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 0 [0/74]\tloss: 4.204412\n",
            "Train Epoch: 0 [10/74]\tloss: 3.556373\n",
            "Train Epoch: 0 [20/74]\tloss: 3.539596\n",
            "Train Epoch: 0 [30/74]\tloss: 3.293774\n",
            "Train Epoch: 0 [40/74]\tloss: 3.085907\n",
            "Train Epoch: 0 [50/74]\tloss: 2.825827\n",
            "Train Epoch: 0 [60/74]\tloss: 2.529898\n",
            "Train Epoch: 0 [70/74]\tloss: 2.343734\n",
            "[0] Validation Loss: 2.0837, Accuracy: 59.7973%\n",
            "Train Epoch: 1 [0/74]\tloss: 1.823646\n",
            "Train Epoch: 1 [10/74]\tloss: 2.022751\n",
            "Train Epoch: 1 [20/74]\tloss: 1.942212\n",
            "Train Epoch: 1 [30/74]\tloss: 1.798275\n",
            "Train Epoch: 1 [40/74]\tloss: 1.517177\n",
            "Train Epoch: 1 [50/74]\tloss: 1.282930\n",
            "Train Epoch: 1 [60/74]\tloss: 1.580415\n",
            "Train Epoch: 1 [70/74]\tloss: 1.227101\n",
            "[1] Validation Loss: 1.3825, Accuracy: 80.7432%\n",
            "Train Epoch: 2 [0/74]\tloss: 1.094393\n",
            "Train Epoch: 2 [10/74]\tloss: 0.790519\n",
            "Train Epoch: 2 [20/74]\tloss: 0.924693\n",
            "Train Epoch: 2 [30/74]\tloss: 0.951400\n",
            "Train Epoch: 2 [40/74]\tloss: 0.694933\n",
            "Train Epoch: 2 [50/74]\tloss: 0.849738\n",
            "Train Epoch: 2 [60/74]\tloss: 0.650016\n",
            "Train Epoch: 2 [70/74]\tloss: 0.736409\n",
            "[2] Validation Loss: 1.1126, Accuracy: 82.4324%\n",
            "Train Epoch: 3 [0/74]\tloss: 0.489262\n",
            "Train Epoch: 3 [10/74]\tloss: 0.442626\n",
            "Train Epoch: 3 [20/74]\tloss: 0.363951\n",
            "Train Epoch: 3 [30/74]\tloss: 0.572295\n",
            "Train Epoch: 3 [40/74]\tloss: 0.507064\n",
            "Train Epoch: 3 [50/74]\tloss: 0.354765\n",
            "Train Epoch: 3 [60/74]\tloss: 0.365140\n",
            "Train Epoch: 3 [70/74]\tloss: 0.315860\n",
            "[3] Validation Loss: 0.8915, Accuracy: 86.8243%\n",
            "Train Epoch: 4 [0/74]\tloss: 0.215995\n",
            "Train Epoch: 4 [10/74]\tloss: 0.233343\n",
            "Train Epoch: 4 [20/74]\tloss: 0.187209\n",
            "Train Epoch: 4 [30/74]\tloss: 0.203925\n",
            "Train Epoch: 4 [40/74]\tloss: 0.227183\n",
            "Train Epoch: 4 [50/74]\tloss: 0.234917\n",
            "Train Epoch: 4 [60/74]\tloss: 0.195485\n",
            "Train Epoch: 4 [70/74]\tloss: 0.267515\n",
            "[4] Validation Loss: 0.7991, Accuracy: 87.1622%\n",
            "Train Epoch: 5 [0/74]\tloss: 0.112343\n",
            "Train Epoch: 5 [10/74]\tloss: 0.173585\n",
            "Train Epoch: 5 [20/74]\tloss: 0.113090\n",
            "Train Epoch: 5 [30/74]\tloss: 0.127539\n",
            "Train Epoch: 5 [40/74]\tloss: 0.130025\n",
            "Train Epoch: 5 [50/74]\tloss: 0.101244\n",
            "Train Epoch: 5 [60/74]\tloss: 0.102075\n",
            "Train Epoch: 5 [70/74]\tloss: 0.142672\n",
            "[5] Validation Loss: 0.6965, Accuracy: 88.1757%\n",
            "Train Epoch: 6 [0/74]\tloss: 0.086272\n",
            "Train Epoch: 6 [10/74]\tloss: 0.073188\n",
            "Train Epoch: 6 [20/74]\tloss: 0.106859\n",
            "Train Epoch: 6 [30/74]\tloss: 0.057005\n",
            "Train Epoch: 6 [40/74]\tloss: 0.059503\n",
            "Train Epoch: 6 [50/74]\tloss: 0.070962\n",
            "Train Epoch: 6 [60/74]\tloss: 0.082219\n",
            "Train Epoch: 6 [70/74]\tloss: 0.061471\n",
            "[6] Validation Loss: 0.6918, Accuracy: 87.8378%\n",
            "Train Epoch: 7 [0/74]\tloss: 0.069903\n",
            "Train Epoch: 7 [10/74]\tloss: 0.074500\n",
            "Train Epoch: 7 [20/74]\tloss: 0.052311\n",
            "Train Epoch: 7 [30/74]\tloss: 0.050474\n",
            "Train Epoch: 7 [40/74]\tloss: 0.053961\n",
            "Train Epoch: 7 [50/74]\tloss: 0.046173\n",
            "Train Epoch: 7 [60/74]\tloss: 0.066446\n",
            "Train Epoch: 7 [70/74]\tloss: 0.048807\n",
            "[7] Validation Loss: 0.6482, Accuracy: 89.1892%\n",
            "Train Epoch: 8 [0/74]\tloss: 0.050655\n",
            "Train Epoch: 8 [10/74]\tloss: 0.041653\n",
            "Train Epoch: 8 [20/74]\tloss: 0.046345\n",
            "Train Epoch: 8 [30/74]\tloss: 0.047581\n",
            "Train Epoch: 8 [40/74]\tloss: 0.052894\n",
            "Train Epoch: 8 [50/74]\tloss: 0.033089\n",
            "Train Epoch: 8 [60/74]\tloss: 0.038398\n",
            "Train Epoch: 8 [70/74]\tloss: 0.040645\n",
            "[8] Validation Loss: 0.6128, Accuracy: 87.8378%\n",
            "Train Epoch: 9 [0/74]\tloss: 0.026954\n",
            "Train Epoch: 9 [10/74]\tloss: 0.030519\n",
            "Train Epoch: 9 [20/74]\tloss: 0.041517\n",
            "Train Epoch: 9 [30/74]\tloss: 0.041323\n",
            "Train Epoch: 9 [40/74]\tloss: 0.034937\n",
            "Train Epoch: 9 [50/74]\tloss: 0.076527\n",
            "Train Epoch: 9 [60/74]\tloss: 0.034495\n",
            "Train Epoch: 9 [70/74]\tloss: 0.032373\n",
            "[9] Validation Loss: 0.6145, Accuracy: 88.5135%\n",
            "Train Epoch: 10 [0/74]\tloss: 0.028257\n",
            "Train Epoch: 10 [10/74]\tloss: 0.034467\n",
            "Train Epoch: 10 [20/74]\tloss: 0.028888\n",
            "Train Epoch: 10 [30/74]\tloss: 0.023313\n",
            "Train Epoch: 10 [40/74]\tloss: 0.021935\n",
            "Train Epoch: 10 [50/74]\tloss: 0.025078\n",
            "Train Epoch: 10 [60/74]\tloss: 0.022896\n",
            "Train Epoch: 10 [70/74]\tloss: 0.025329\n",
            "[10] Validation Loss: 0.6007, Accuracy: 87.5000%\n",
            "Train Epoch: 11 [0/74]\tloss: 0.027645\n",
            "Train Epoch: 11 [10/74]\tloss: 0.018870\n",
            "Train Epoch: 11 [20/74]\tloss: 0.027108\n",
            "Train Epoch: 11 [30/74]\tloss: 0.027013\n",
            "Train Epoch: 11 [40/74]\tloss: 0.022594\n",
            "Train Epoch: 11 [50/74]\tloss: 0.024547\n",
            "Train Epoch: 11 [60/74]\tloss: 0.026853\n",
            "Train Epoch: 11 [70/74]\tloss: 0.029725\n",
            "[11] Validation Loss: 0.5819, Accuracy: 88.8514%\n",
            "Train Epoch: 12 [0/74]\tloss: 0.016937\n",
            "Train Epoch: 12 [10/74]\tloss: 0.019786\n",
            "Train Epoch: 12 [20/74]\tloss: 0.028859\n",
            "Train Epoch: 12 [30/74]\tloss: 0.020236\n",
            "Train Epoch: 12 [40/74]\tloss: 0.017158\n",
            "Train Epoch: 12 [50/74]\tloss: 0.023984\n",
            "Train Epoch: 12 [60/74]\tloss: 0.019644\n",
            "Train Epoch: 12 [70/74]\tloss: 0.018048\n",
            "[12] Validation Loss: 0.5669, Accuracy: 88.5135%\n",
            "Train Epoch: 13 [0/74]\tloss: 0.018676\n",
            "Train Epoch: 13 [10/74]\tloss: 0.020181\n",
            "Train Epoch: 13 [20/74]\tloss: 0.022608\n",
            "Train Epoch: 13 [30/74]\tloss: 0.014668\n",
            "Train Epoch: 13 [40/74]\tloss: 0.019837\n",
            "Train Epoch: 13 [50/74]\tloss: 0.018356\n",
            "Train Epoch: 13 [60/74]\tloss: 0.018024\n",
            "Train Epoch: 13 [70/74]\tloss: 0.019295\n",
            "[13] Validation Loss: 0.5834, Accuracy: 87.8378%\n",
            "Train Epoch: 14 [0/74]\tloss: 0.016565\n",
            "Train Epoch: 14 [10/74]\tloss: 0.016946\n",
            "Train Epoch: 14 [20/74]\tloss: 0.016176\n",
            "Train Epoch: 14 [30/74]\tloss: 0.014831\n",
            "Train Epoch: 14 [40/74]\tloss: 0.014619\n",
            "Train Epoch: 14 [50/74]\tloss: 0.019998\n",
            "Train Epoch: 14 [60/74]\tloss: 0.018091\n",
            "Train Epoch: 14 [70/74]\tloss: 0.018706\n",
            "[14] Validation Loss: 0.5695, Accuracy: 88.8514%\n",
            "Train Epoch: 15 [0/74]\tloss: 0.013262\n",
            "Train Epoch: 15 [10/74]\tloss: 0.014730\n",
            "Train Epoch: 15 [20/74]\tloss: 0.017647\n",
            "Train Epoch: 15 [30/74]\tloss: 0.023481\n",
            "Train Epoch: 15 [40/74]\tloss: 0.013490\n",
            "Train Epoch: 15 [50/74]\tloss: 0.014854\n",
            "Train Epoch: 15 [60/74]\tloss: 0.026720\n",
            "Train Epoch: 15 [70/74]\tloss: 0.015358\n",
            "[15] Validation Loss: 0.5753, Accuracy: 87.8378%\n",
            "Train Epoch: 16 [0/74]\tloss: 0.018633\n",
            "Train Epoch: 16 [10/74]\tloss: 0.013665\n",
            "Train Epoch: 16 [20/74]\tloss: 0.018755\n",
            "Train Epoch: 16 [30/74]\tloss: 0.015132\n",
            "Train Epoch: 16 [40/74]\tloss: 0.014934\n",
            "Train Epoch: 16 [50/74]\tloss: 0.017973\n",
            "Train Epoch: 16 [60/74]\tloss: 0.014068\n",
            "Train Epoch: 16 [70/74]\tloss: 0.011688\n",
            "[16] Validation Loss: 0.5728, Accuracy: 88.5135%\n",
            "Train Epoch: 17 [0/74]\tloss: 0.015559\n",
            "Train Epoch: 17 [10/74]\tloss: 0.010953\n",
            "Train Epoch: 17 [20/74]\tloss: 0.014124\n",
            "Train Epoch: 17 [30/74]\tloss: 0.013797\n",
            "Train Epoch: 17 [40/74]\tloss: 0.013894\n",
            "Train Epoch: 17 [50/74]\tloss: 0.011692\n",
            "Train Epoch: 17 [60/74]\tloss: 0.012002\n",
            "Train Epoch: 17 [70/74]\tloss: 0.011191\n",
            "[17] Validation Loss: 0.5686, Accuracy: 88.5135%\n",
            "Train Epoch: 18 [0/74]\tloss: 0.014316\n",
            "Train Epoch: 18 [10/74]\tloss: 0.013694\n",
            "Train Epoch: 18 [20/74]\tloss: 0.010094\n",
            "Train Epoch: 18 [30/74]\tloss: 0.017088\n",
            "Train Epoch: 18 [40/74]\tloss: 0.012564\n",
            "Train Epoch: 18 [50/74]\tloss: 0.017536\n",
            "Train Epoch: 18 [60/74]\tloss: 0.010997\n",
            "Train Epoch: 18 [70/74]\tloss: 0.011310\n",
            "[18] Validation Loss: 0.5758, Accuracy: 88.1757%\n",
            "Train Epoch: 19 [0/74]\tloss: 0.019562\n",
            "Train Epoch: 19 [10/74]\tloss: 0.014390\n",
            "Train Epoch: 19 [20/74]\tloss: 0.014583\n",
            "Train Epoch: 19 [30/74]\tloss: 0.012402\n",
            "Train Epoch: 19 [40/74]\tloss: 0.010787\n",
            "Train Epoch: 19 [50/74]\tloss: 0.009003\n",
            "Train Epoch: 19 [60/74]\tloss: 0.013460\n",
            "Train Epoch: 19 [70/74]\tloss: 0.013387\n",
            "[19] Validation Loss: 0.5654, Accuracy: 88.5135%\n",
            "Train Epoch: 20 [0/74]\tloss: 0.012936\n",
            "Train Epoch: 20 [10/74]\tloss: 0.013230\n",
            "Train Epoch: 20 [20/74]\tloss: 0.012156\n",
            "Train Epoch: 20 [30/74]\tloss: 0.009804\n",
            "Train Epoch: 20 [40/74]\tloss: 0.010629\n",
            "Train Epoch: 20 [50/74]\tloss: 0.010611\n",
            "Train Epoch: 20 [60/74]\tloss: 0.012161\n",
            "Train Epoch: 20 [70/74]\tloss: 0.016627\n",
            "[20] Validation Loss: 0.5701, Accuracy: 88.8514%\n",
            "Train Epoch: 21 [0/74]\tloss: 0.010887\n",
            "Train Epoch: 21 [10/74]\tloss: 0.011874\n",
            "Train Epoch: 21 [20/74]\tloss: 0.012126\n",
            "Train Epoch: 21 [30/74]\tloss: 0.012770\n",
            "Train Epoch: 21 [40/74]\tloss: 0.014382\n",
            "Train Epoch: 21 [50/74]\tloss: 0.012112\n",
            "Train Epoch: 21 [60/74]\tloss: 0.012624\n",
            "Train Epoch: 21 [70/74]\tloss: 0.016701\n",
            "[21] Validation Loss: 0.5716, Accuracy: 88.5135%\n",
            "Train Epoch: 22 [0/74]\tloss: 0.013344\n",
            "Train Epoch: 22 [10/74]\tloss: 0.016615\n",
            "Train Epoch: 22 [20/74]\tloss: 0.013144\n",
            "Train Epoch: 22 [30/74]\tloss: 0.016074\n",
            "Train Epoch: 22 [40/74]\tloss: 0.010610\n",
            "Train Epoch: 22 [50/74]\tloss: 0.013659\n",
            "Train Epoch: 22 [60/74]\tloss: 0.011536\n",
            "Train Epoch: 22 [70/74]\tloss: 0.008679\n",
            "[22] Validation Loss: 0.5671, Accuracy: 88.1757%\n",
            "Train Epoch: 23 [0/74]\tloss: 0.013389\n",
            "Train Epoch: 23 [10/74]\tloss: 0.010746\n",
            "Train Epoch: 23 [20/74]\tloss: 0.010375\n",
            "Train Epoch: 23 [30/74]\tloss: 0.012346\n",
            "Train Epoch: 23 [40/74]\tloss: 0.015194\n",
            "Train Epoch: 23 [50/74]\tloss: 0.031336\n",
            "Train Epoch: 23 [60/74]\tloss: 0.011008\n",
            "Train Epoch: 23 [70/74]\tloss: 0.011644\n",
            "[23] Validation Loss: 0.5588, Accuracy: 87.5000%\n",
            "Train Epoch: 24 [0/74]\tloss: 0.008996\n",
            "Train Epoch: 24 [10/74]\tloss: 0.016786\n",
            "Train Epoch: 24 [20/74]\tloss: 0.011580\n",
            "Train Epoch: 24 [30/74]\tloss: 0.010748\n",
            "Train Epoch: 24 [40/74]\tloss: 0.015079\n",
            "Train Epoch: 24 [50/74]\tloss: 0.010874\n",
            "Train Epoch: 24 [60/74]\tloss: 0.012991\n",
            "Train Epoch: 24 [70/74]\tloss: 0.013719\n",
            "[24] Validation Loss: 0.5676, Accuracy: 88.1757%\n",
            "[FINAL] Test Loss: 0.5759, Accuracy: 90.9396%\n",
            "Best Accuracy:  89.1891891891892\n",
            "Elapsed Time: 0h, 30m, 20s\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██</td></tr><tr><td>Test Accuracy</td><td>▁</td></tr><tr><td>Test Loss</td><td>▁</td></tr><tr><td>Train Loss</td><td>█▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▆▆▇█████████████████████</td></tr><tr><td>Validation Loss</td><td>█▅▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>24</td></tr><tr><td>Test Accuracy</td><td>90.9396</td></tr><tr><td>Test Loss</td><td>0.57588</td></tr><tr><td>Train Loss</td><td>0.01295</td></tr><tr><td>Validation Accuracy</td><td>88.17568</td></tr><tr><td>Validation Loss</td><td>0.56756</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">AdamP_with_CosineAnnealingLR</strong> at: <a href='https://wandb.ai/parkdoi-gachon-university/CUB_Transfer_Learning/runs/xxc0q265' target=\"_blank\">https://wandb.ai/parkdoi-gachon-university/CUB_Transfer_Learning/runs/xxc0q265</a><br/> View project at: <a href='https://wandb.ai/parkdoi-gachon-university/CUB_Transfer_Learning' target=\"_blank\">https://wandb.ai/parkdoi-gachon-university/CUB_Transfer_Learning</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20241025_125619-xxc0q265/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}